version: '3'

services:
  # Kafka Ecosystem
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181

  kafka:
    image: confluentinc/cp-kafka:7.4.0
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

  kafka-connect:
    image: confluentinc/cp-kafka-connect:7.4.0
    depends_on:
      - kafka
    ports:
      - "8083:8083"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: kafka:29092
      CONNECT_REST_ADVERTISED_HOST_NAME: kafka-connect
      CONNECT_GROUP_ID: compose-connect-group
      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components"
      # Snowflake Connector Configuration - REPLACE WITH YOUR ACTUAL VALUES
      CONNECT_SNOWFLAKE_URL: mhwkfau-mf75876.snowflakecomputing.com # e.g., youraccount.snowflakecomputing.com
      CONNECT_SNOWFLAKE_USER: KAFKA_SINK_USER
      CONNECT_SNOWFLAKE_PRIVATE_KEY: "MIIFNTBfBgkqhkiG9w0BBQ0wUjAxBgkqhkiG9w0BBQwwJAQQeMKycBTxUfqisx4OHaMTbAICCAAwDAYIKoZIhvcNAgkFADAdBglghkgBZQMEASoEEEm0Wn1DCkD75LAqWtB4fQIEggTQTpNmXxDNc6jG+5v7DEUpSgqjI3yxPcLSOnKWGTeZgYfzBB4zG3CT06H40O+haM4jDEcTnTkJLOtZjzyff7CXf4prNqNn0nWDsgqOpQ3rFgGRAgnlxlgIvjDDbgO453KNxOXhHNOUJ8dPfQgjTvoP6Cx+c6aORvZ6V0RQvLhewbijng582XK/GCblwuB7zA/XWYajKvf6rfcQ6EymG0unPkCyfXRFA5UK1CublVUf93ju2l0u3b81yBuwipk26fksnd1Z++uwDXQ5hqXV9VGNQAMfNbqSRIS12DFJMUBdkoYPJ46n3dU5UHqPwcTT0ROsGY7yx1evTexldVIoR8wraqCFD/xbhrZCdGX6qYE5ACdvbytL1YTinvlEEtPW3FhROz79/SJkI1bRkJLSC6PuU2yreiyQsH9NeGNrBRjrCFQJDEbI0OoMEr7s5pusy+1TXAq4qKaAN9wofCLUSKvtYIHGiZkhe/cOYcjtsp9gUzg0CLeUlrzP2vzc7LHM4aw2fTSxTk/EVhfgJoZ7ZRvr/OjDdSOHwiV+IwDfBmp9AWswixQhcNKGXk4pcURzEhPqz1KI88mG5yAPgxcFkfSR1/q/cnjSIkrgBNOXnQZfn4UXyqMrkbEM3dpyR7WX8UnKqCDbTF+Jl8z0089l+8tdTTUfniFvjtoQhRQ9pDfeLDPiBU8fwlh+1e4/8GPP9w97f11lUZOfqnsKp/dY0M5Cx6LSMVfLTwHx1NnhGEnD9BthC84z8wEMRzF8I+7wPwHzYF93GpumvWIFy9OCI51+FpnCitJqcVYCuJyVMGxyNWvH795yBRY261OcxG0AublA2lJ5zbVb6BsSZSWQ3Nqnd+WJTdcXMKz5tNUCZ9nBPBq79RSz+YF8eaTldG/68KXOy09tsRanwkwr9klsyYsN9I20QVi29qqWVppw8GDZNYqw8G99Y8M/kurPQSUfmM/J692UZSrpHf0qyFlaUBCV+a/KfDCF1aRVnoBqqXsTIOi7mhRxEO+15KSWbUayFLMPGNUrhkd3oPFpmwUkx44fdyG2rr373/0Exq/Zg6VqnlDTTVACkbLewKlWiAnJEPQDIZBgYqvxNbXr9bhbkvtTMx8Onp/BcU62h5aQuIYQo50zpxHeMtmKUAqsghp4bPl4EXY+sHaq983nIgQtm7pOSo37/qZeb8nc/3jUIN+BmgkelXaFB7lQvYuOroL/05KnjLdFGR9S9y1ONn2/oiRHO9DlbrcqX3qtDCvdcF4/Wn/+NsFwgSerO+bd7y6Cjne/RIv6v8X32FiHhyi72z9hDmBJTrzUAsG8ISsbfRTrBdPYo7i4jH7CvHvdljfec2FRZp+JhrMKQHRsDTHdae5otG/aDdx8xtdQdUT79+f5zU7Cge4cxY9QIyjS05rvRChgwhOUAL0I3g+4rg4eOa7B/FiLn0DwYkQcgAytbL8cD61IXFuRdjJC8gFpuNqGD3svAMxOcHpyJepV8slSqaS2qOOw5VQ9W7cUfqR7des+Gs6stvmW7aJNlDcGZr2DMtdWcA4AC8u9u7INnOqFzcYuJXzf1oW1EwbGEN0MIxTE6MWSf2dFAYvFcyxnp4PctKL7ls517Zwq/SYZUQCVmBb6JudjzIDP+4cS5N9PLem3xZc="
      CONNECT_SNOWFLAKE_PRIVATE_KEY_PASSPHRASE: "T3mp.4ccount" # Your passphrase
      CONNECT_SNOWFLAKE_DATABASE: ACTIVITY_DB
      CONNECT_SNOWFLAKE_SCHEMA: RAW_DATA
      CONNECT_SNOWFLAKE_WAREHOUSE: KAFKA_CONNECT_WH # Optional, if not default
    # Install JDBC and Snowflake connectors
    command: 
      - bash 
      - -c 
      - |
        confluent-hub install --no-prompt confluentinc/kafka-connect-jdbc:10.7.0 && \
        confluent-hub install --no-prompt snowflakeinc/snowflake-kafka-connector:latest && \
        /etc/confluent/docker/run

  kafka-init:
    image: confluentinc/cp-kafka:7.4.0 # Image with kafka-topics.sh and curl
    depends_on:
      - kafka
      - kafka-connect
    volumes:
      - ./scripts/init-kafka.sh:/tmp/init-kafka.sh
      - ./docker/connector-configs/snowflake-sink-raw-config.json:/config/snowflake-sink-raw-config.json
      - ./docker/connector-configs/snowflake-sink-processed-config.json:/config/snowflake-sink-processed-config.json
      # If your configs are in a sub-directory, adjust the mount:
      # - ./connector-configs:/config 
    command: ["sh", "/tmp/init-kafka.sh"]
    # If the script fails, this container will exit. 
    # You might want to add restart policies depending on desired behavior.

  # Kafka Console (UI)
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    depends_on:
      - kafka
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181

  # Visualization
  # grafana:
  #   image: grafana/grafana:latest
  #   ports:
  #     - "3000:3000"
  #   environment:
  #     GF_INSTALL_PLUGINS: grafana-snowflake-datasource
  #     GF_SECURITY_ADMIN_USER: admin
  #     GF_SECURITY_ADMIN_PASSWORD: admin
  #     GF_DASHBOARDS_DEFAULT_HOME_DASHBOARD_PATH: /etc/grafana/dashboards/activity_monitoring_dashboard.json
  #     # Additional configuration to fix the issues
  #     GF_FEATURE_TOGGLES_ENABLE: publicDashboards
  #   volumes:
  #     - ./docker/grafana-dashboards:/etc/grafana/dashboards
  #     - ./docker/grafana-provisioning:/etc/grafana/provisioning
  #     - grafana-data:/var/lib/grafana
  #   depends_on:
  #     - kafka

  spark:
    image: bitnami/spark:3.3.0
    depends_on:
      - kafka
    networks:
      - default  # Share the same network as Kafka
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:29092  # Docker service name
    volumes:
      - ./spark-streaming:/app
      - ./log4j2.properties:/opt/bitnami/spark/conf/log4j2.properties
      - ./checkpoint:/tmp/checkpoint
    command: >
      /opt/bitnami/spark/bin/spark-submit
      --master local[*]
      --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0
      /app/activity_detection.py

volumes:
  grafana-data: